{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d33885",
   "metadata": {},
   "source": [
    "Land cover is the bio-physical material present on the Earth's surface. For example - water bodies, forests, bare soil, man-made surfaces.\n",
    "\n",
    "Land use is the purpose or activity of the surface for human consumption. For example - agriculture, residential, commercial, conservation.\n",
    "\n",
    "Land cover can be analysed for desired geographical region through satelite imagery. The trend of changed land cover can be used to understand the pattern of land use, and plan accordingly.\n",
    "\n",
    "While a standard photo uses only Red, Green, and Blue channels, multi-spectral satellites like (Sentinel-2)[https://dataspace.copernicus.eu/data-collections/copernicus-sentinel-data/sentinel-2] capture \"invisible\" light across 12 distinct spectral bands. These extra bands, such as Infrared, allow us to detect \"spectral signatures\" that differentiate materials - like grass versus green paint.\n",
    "\n",
    "For machine learning, we reshape this data into a matrix where each of the  HÃ—W  pixels is a sample and each band is a feature. This high-dimensional depth enables algorithms like K-Means to group land covers with far greater precision than standard 3-band imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd2d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read data as matrix of shape (12, 1987, 2500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.    , 0.    , 0.    , ..., 0.0277, 0.0298, 0.0302],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0337, 0.0293, 0.0265],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0248, 0.0291, 0.0235],\n",
       "        ...,\n",
       "        [0.1072, 0.0764, 0.0362, ..., 0.0152, 0.0286, 0.0501],\n",
       "        [0.1066, 0.0878, 0.022 , ..., 0.0164, 0.023 , 0.0594],\n",
       "        [0.1162, 0.0892, 0.0608, ..., 0.0381, 0.0504, 0.0943]],\n",
       "\n",
       "       [[0.    , 0.    , 0.    , ..., 0.0409, 0.0399, 0.0448],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0509, 0.0443, 0.0443],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0443, 0.0517, 0.028 ],\n",
       "        ...,\n",
       "        [0.1316, 0.1014, 0.0516, ..., 0.0337, 0.0553, 0.0818],\n",
       "        [0.1282, 0.1054, 0.046 , ..., 0.0325, 0.0492, 0.084 ],\n",
       "        [0.1498, 0.1112, 0.082 , ..., 0.0687, 0.071 , 0.1136]],\n",
       "\n",
       "       [[0.    , 0.    , 0.    , ..., 0.0322, 0.0349, 0.0373],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0379, 0.0331, 0.032 ],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0331, 0.0354, 0.0245],\n",
       "        ...,\n",
       "        [0.1454, 0.105 , 0.0485, ..., 0.0236, 0.0447, 0.1006],\n",
       "        [0.1464, 0.1136, 0.0388, ..., 0.0261, 0.0412, 0.0954],\n",
       "        [0.1634, 0.125 , 0.0871, ..., 0.0778, 0.0816, 0.1192]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.    , 0.    , 0.    , ..., 0.2895, 0.2868, 0.2809],\n",
       "        [0.    , 0.    , 0.    , ..., 0.2784, 0.2787, 0.2775],\n",
       "        [0.    , 0.    , 0.    , ..., 0.2722, 0.2752, 0.278 ],\n",
       "        ...,\n",
       "        [0.191 , 0.19  , 0.1932, ..., 0.204 , 0.2061, 0.208 ],\n",
       "        [0.1953, 0.1955, 0.1991, ..., 0.2044, 0.2063, 0.2078],\n",
       "        [0.1975, 0.1984, 0.2021, ..., 0.2033, 0.2047, 0.2058]],\n",
       "\n",
       "       [[0.    , 0.    , 0.    , ..., 0.1808, 0.1799, 0.1593],\n",
       "        [0.    , 0.    , 0.    , ..., 0.1823, 0.1748, 0.1457],\n",
       "        [0.    , 0.    , 0.    , ..., 0.1687, 0.1557, 0.1269],\n",
       "        ...,\n",
       "        [0.213 , 0.1812, 0.1706, ..., 0.1539, 0.1817, 0.2154],\n",
       "        [0.2162, 0.1983, 0.1849, ..., 0.1794, 0.1949, 0.2113],\n",
       "        [0.2031, 0.2029, 0.1957, ..., 0.2068, 0.2099, 0.2096]],\n",
       "\n",
       "       [[0.    , 0.    , 0.    , ..., 0.0827, 0.0822, 0.0728],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0852, 0.0816, 0.0674],\n",
       "        [0.    , 0.    , 0.    , ..., 0.0816, 0.0757, 0.0603],\n",
       "        ...,\n",
       "        [0.1911, 0.146 , 0.1253, ..., 0.0908, 0.1134, 0.1479],\n",
       "        [0.1946, 0.1651, 0.1396, ..., 0.1111, 0.1286, 0.1536],\n",
       "        [0.1804, 0.1723, 0.1519, ..., 0.1381, 0.1507, 0.1662]]],\n",
       "      shape=(12, 1987, 2500), dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "RAW_DATA_DIR = PROJECT_ROOT / 'data' / 'raw'\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tiff_path = RAW_DATA_DIR / 'merged.tiff' # satellite very big file\n",
    "\n",
    "# best practice: use a context manager so the file is always closed\n",
    "with rasterio.open(tiff_path) as src:\n",
    "    data = src.read()\n",
    "\n",
    "# now data is 12 god arrays = 12 photographs and each photograph/array is a h*w matrix\n",
    "# its a 3d numpy array/tensor\n",
    "# so assuming 12 photos stacked left to right as red color = photo0, blue = photo1 and so on\n",
    "# with each photo being its own 2d matrix  beffore reshape\n",
    "# after reshape its 12 columsn of bands and each row is one sample = one pixel, shape (h*w,12)\n",
    "# we arrange this way since ML convention is X (rows) = things you want to study (pixel/loc) and y (columns) = attributes of those things\n",
    "\n",
    "print(f'\\nRead data as matrix of shape {data.shape}')\n",
    "\n",
    "data\n",
    "# means we have say a point at h,w like x,y which has 12 values (one for each color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa490fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4967500, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: update these values from the shape of the matrix\n",
    "\n",
    "N, H, W = data.shape # simple easy, aka tuple unpacking\n",
    "\n",
    "# reshape the data to (H x W, N)\n",
    "# the data in a row should correspond to a pixel\n",
    "\n",
    "# sanity check\n",
    "#random_pixel = (118, 256) # (h, w) Output: Array of 12 numbers (one per band)\n",
    "#display(data[:, random_pixel[0], random_pixel[1]])\n",
    "\n",
    "# init it was N H W now we want H W N, simply like index of shape tuple\n",
    "# without transpose wed get 12 pixels from Band 0, NOT 12 bands for Pixel 0\n",
    "data = data.transpose(1, 2, 0).reshape(H * W, N)\n",
    "#display(data[random_pixel[0] * W + random_pixel[1]])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23917a",
   "metadata": {},
   "source": [
    "visually\n",
    "\n",
    "**og (bands, h,w)**\n",
    "`Memory: [B0P0, B0P1, ..., B0P_last, B1P0, B1P1, ..., B11P_last]`\n",
    "**after transpose (h,w, bands)**\n",
    "`Memory: [P0B0, P0B1, ..., P0B11, P1B0, P1B1, ..., P_lastB11]`\n",
    "**after reshape (h*w, bands)**\n",
    "```\n",
    "Row 0: [P0B0, P0B1, ..., P0B11]\n",
    "Row 1: [P1B0, P1B1, ..., P1B11]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import Pipeline, KMeans and StandardScaler from sklearn\n",
    "# it is important to \"normalize\" the data before training (via std scaler)\n",
    "# TODO: create a pipeline and use the \"fit\" method to train the model\n",
    "\n",
    "k = 6  # choose number of land-cover clusters\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),(\"kmeans\", KMeans(n_clusters=k, random_state=42, n_init=\"auto\"))\n",
    "]).fit(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
